{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis on all-selections.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.queries import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read `all-selections.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv('all-selections.csv')\n",
    "df_original.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract only the useful columns:\n",
    " - `'name'`\n",
    " - `'winery_name'`\n",
    " - `'type'`\n",
    " - `'matched_id'`\n",
    "\n",
    "Additional actions:\n",
    " - rename `'matched_id'` to `'correct_id'`.\n",
    "\n",
    "This is because the only correct match is `'matched_id'`, and the columns `'matched_name'`, `'matched_winery_name'` are incorrect. I have to build them again by querying the ElasticSearch index by id.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_original.get(['name', 'winery_name', 'type', 'matched_id'])\n",
    "df = df.rename(columns={'matched_id': 'correct_id'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the correct values for `'name'`, `'winery_name'` and`'type'`:\n",
    " - Query the ElasticSearch index by id\n",
    " - generate dictionary from id to names\n",
    " - add new columns to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_by_id(list(df['correct_id']))\n",
    "display(response[0])\n",
    "\n",
    "id_mapping = {r['id']: r for r in response}\n",
    "\n",
    "df['correct_name'] = df['correct_id'].map(lambda x: id_mapping[x]['name'])\n",
    "df['correct_winery_name'] = df['correct_id'].map(lambda x: id_mapping[x]['winery_name'])\n",
    "df['correct_type'] = df['correct_id'].map(lambda x: id_mapping[x]['type'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(df['correct_type'] != df['type'])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build vocabulary of all words\n",
    "\n",
    "And apply additional preprocessing\n",
    "\n",
    "TODO: incorporate this additional preprocessing in the onboarding pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def strip_accents(text: str):\n",
    "    nfkd_form = unicodedata.normalize('NFKD', text)\n",
    "    return nfkd_form.encode('ASCII', 'ignore').decode()\n",
    "\n",
    "def remove_special_characters(text: str):\n",
    "    return re.sub('\\W', ' ', text)\n",
    "\n",
    "def preprocessing(input_string):\n",
    "    return strip_accents(remove_special_characters(input_string)).lower()\n",
    "\n",
    "def tokenize(preprocessed_text):\n",
    "    return re.findall(r'[\\w.]+(?:\\B\\S)*', preprocessed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_name = sorted(set([word for doc in df['name'].map(tokenize) for word in doc]))\n",
    "vocabulary_winery_name = sorted(set([word for doc in df['winery_name'].map(tokenize) for word in doc]))\n",
    "\n",
    "print(len(vocabulary_name))\n",
    "print(len(vocabulary_winery_name))\n",
    "\n",
    "vocabulary_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get document frequencies of each word in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.word_occurrences import get_all_occurrences_db\n",
    "\n",
    "get_all_occurrences_db(vocabulary_name, 'word_frequency_name.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.word_occurrences import get_all_occurrences_db\n",
    "\n",
    "get_all_occurrences_db(vocabulary_winery_name, 'word_frequency_winery_name.db')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vinoteqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
